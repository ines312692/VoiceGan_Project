{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Notebook 1: Exploration des Données\n",
    "\n",
    "Ce notebook explore le dataset pour la conversion vocale A→B.\n",
    "\n",
    "**Objectifs:**\n",
    "- Charger et analyser le dataset\n",
    "- Visualiser les distributions audio\n",
    "- Analyser les caractéristiques des locuteurs\n",
    "- Vérifier la qualité des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des données\n",
    "DATA_DIR = Path('../data')\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "VAL_DIR = DATA_DIR / 'val'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "\n",
    "# Paramètres audio\n",
    "SAMPLE_RATE = 22050\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 256\n",
    "N_MELS = 80\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Train directory exists: {TRAIN_DIR.exists()}\")\n",
    "print(f\"Val directory exists: {VAL_DIR.exists()}\")\n",
    "print(f\"Test directory exists: {TEST_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse de la Structure des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(data_dir):\n",
    "    \"\"\"Analyser la structure du dataset\"\"\"\n",
    "    speakers = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    stats = []\n",
    "    for speaker_dir in speakers:\n",
    "        audio_files = list(speaker_dir.glob('*.wav')) + list(speaker_dir.glob('*.flac'))\n",
    "        \n",
    "        stats.append({\n",
    "            'speaker': speaker_dir.name,\n",
    "            'num_files': len(audio_files),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "# Analyser chaque split\n",
    "print(\"\\n=== TRAIN SET ===\")\n",
    "train_stats = analyze_dataset_structure(TRAIN_DIR)\n",
    "print(train_stats)\n",
    "print(f\"\\nTotal speakers: {len(train_stats)}\")\n",
    "print(f\"Total files: {train_stats['num_files'].sum()}\")\n",
    "print(f\"Average files per speaker: {train_stats['num_files'].mean():.1f}\")\n",
    "\n",
    "print(\"\\n=== VAL SET ===\")\n",
    "val_stats = analyze_dataset_structure(VAL_DIR)\n",
    "print(val_stats)\n",
    "print(f\"Total files: {val_stats['num_files'].sum()}\")\n",
    "\n",
    "print(\"\\n=== TEST SET ===\")\n",
    "test_stats = analyze_dataset_structure(TEST_DIR)\n",
    "print(test_stats)\n",
    "print(f\"Total files: {test_stats['num_files'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (name, stats) in zip(axes, [('Train', train_stats), ('Val', val_stats), ('Test', test_stats)]):\n",
    "    ax.bar(stats['speaker'], stats['num_files'])\n",
    "    ax.set_title(f'{name} Set - Files per Speaker')\n",
    "    ax.set_xlabel('Speaker')\n",
    "    ax.set_ylabel('Number of Files')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse des Propriétés Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_properties(data_dir, num_samples=50):\n",
    "    \"\"\"Analyser les propriétés des fichiers audio\"\"\"\n",
    "    speakers = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    audio_stats = []\n",
    "    \n",
    "    for speaker_dir in tqdm(speakers, desc=\"Analyzing audio\"):\n",
    "        audio_files = list(speaker_dir.glob('*.wav')) + list(speaker_dir.glob('*.flac'))\n",
    "        \n",
    "        # Échantillonner si trop de fichiers\n",
    "        if len(audio_files) > num_samples:\n",
    "            audio_files = np.random.choice(audio_files, num_samples, replace=False)\n",
    "        \n",
    "        for audio_path in audio_files:\n",
    "            try:\n",
    "                y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "                \n",
    "                audio_stats.append({\n",
    "                    'speaker': speaker_dir.name,\n",
    "                    'duration': len(y) / sr,\n",
    "                    'sample_rate': sr,\n",
    "                    'rms': librosa.feature.rms(y=y).mean(),\n",
    "                    'zero_crossing_rate': librosa.feature.zero_crossing_rate(y).mean(),\n",
    "                    'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr).mean(),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {audio_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(audio_stats)\n",
    "\n",
    "# Analyser train set\n",
    "print(\"Analyzing audio properties...\")\n",
    "audio_stats = analyze_audio_properties(TRAIN_DIR, num_samples=30)\n",
    "print(audio_stats.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Duration distribution\n",
    "axes[0, 0].hist(audio_stats['duration'], bins=50, edgecolor='black')\n",
    "axes[0, 0].set_title('Duration Distribution')\n",
    "axes[0, 0].set_xlabel('Duration (seconds)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# RMS distribution\n",
    "axes[0, 1].hist(audio_stats['rms'], bins=50, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('RMS Energy Distribution')\n",
    "axes[0, 1].set_xlabel('RMS')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Spectral centroid by speaker\n",
    "speaker_means = audio_stats.groupby('speaker')['spectral_centroid'].mean().sort_values()\n",
    "axes[1, 0].barh(range(len(speaker_means)), speaker_means.values)\n",
    "axes[1, 0].set_yticks(range(len(speaker_means)))\n",
    "axes[1, 0].set_yticklabels(speaker_means.index)\n",
    "axes[1, 0].set_title('Average Spectral Centroid by Speaker')\n",
    "axes[1, 0].set_xlabel('Spectral Centroid (Hz)')\n",
    "\n",
    "# Zero crossing rate\n",
    "axes[1, 1].boxplot([audio_stats[audio_stats['speaker'] == s]['zero_crossing_rate'].values \n",
    "                     for s in audio_stats['speaker'].unique()],\n",
    "                    labels=audio_stats['speaker'].unique())\n",
    "axes[1, 1].set_title('Zero Crossing Rate by Speaker')\n",
    "axes[1, 1].set_xlabel('Speaker')\n",
    "axes[1, 1].set_ylabel('Zero Crossing Rate')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation d'Exemples Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio_sample(audio_path, title=\"Audio Sample\"):\n",
    "    \"\"\"Visualiser un échantillon audio\"\"\"\n",
    "    # Charger audio\n",
    "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Créer figure\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axes[0])\n",
    "    axes[0].set_title(f'{title} - Waveform')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "    axes[1].set_title('Spectrogram')\n",
    "    fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "    \n",
    "    # Mel-Spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT, \n",
    "                                         hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_db = librosa.amplitude_to_db(mel, ref=np.max)\n",
    "    img = librosa.display.specshow(mel_db, sr=sr, hop_length=HOP_LENGTH,\n",
    "                                   x_axis='time', y_axis='mel', ax=axes[2])\n",
    "    axes[2].set_title('Mel-Spectrogram')\n",
    "    fig.colorbar(img, ax=axes[2], format='%+2.0f dB')\n",
    "    \n",
    "    # MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    img = librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=axes[3])\n",
    "    axes[3].set_title('MFCCs')\n",
    "    axes[3].set_ylabel('MFCC')\n",
    "    fig.colorbar(img, ax=axes[3])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Play audio\n",
    "    print(f\"Duration: {len(y)/sr:.2f}s\")\n",
    "    print(f\"Sample rate: {sr} Hz\")\n",
    "    return ipd.Audio(y, rate=sr)\n",
    "\n",
    "# Sélectionner un fichier aléatoire de chaque locuteur\n",
    "speakers = [d for d in TRAIN_DIR.iterdir() if d.is_dir()][:3]  # 3 premiers speakers\n",
    "\n",
    "for speaker_dir in speakers:\n",
    "    audio_files = list(speaker_dir.glob('*.wav')) + list(speaker_dir.glob('*.flac'))\n",
    "    if audio_files:\n",
    "        sample_file = np.random.choice(audio_files)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Speaker: {speaker_dir.name}\")\n",
    "        print(f\"File: {sample_file.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        audio = visualize_audio_sample(sample_file, f\"Speaker {speaker_dir.name}\")\n",
    "        display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparaison Entre Locuteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les spectrogrammes de 2 locuteurs différents\n",
    "speakers = [d for d in TRAIN_DIR.iterdir() if d.is_dir()][:2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "\n",
    "for i, speaker_dir in enumerate(speakers):\n",
    "    audio_files = list(speaker_dir.glob('*.wav')) + list(speaker_dir.glob('*.flac'))\n",
    "    sample_file = np.random.choice(audio_files)\n",
    "    \n",
    "    # Charger audio\n",
    "    y, sr = librosa.load(sample_file, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'Speaker {speaker_dir.name} - Waveform')\n",
    "    axes[i, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Mel-spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT,\n",
    "                                        hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_db = librosa.amplitude_to_db(mel, ref=np.max)\n",
    "    img = librosa.display.specshow(mel_db, sr=sr, hop_length=HOP_LENGTH,\n",
    "                                   x_axis='time', y_axis='mel', ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'Speaker {speaker_dir.name} - Mel-Spectrogram')\n",
    "    fig.colorbar(img, ax=axes[i, 1], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vérification de la Qualité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(data_dir):\n",
    "    \"\"\"Vérifier la qualité des données\"\"\"\n",
    "    issues = []\n",
    "    speakers = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    for speaker_dir in tqdm(speakers, desc=\"Checking quality\"):\n",
    "        audio_files = list(speaker_dir.glob('*.wav')) + list(speaker_dir.glob('*.flac'))\n",
    "        \n",
    "        for audio_path in audio_files:\n",
    "            try:\n",
    "                y, sr = librosa.load(audio_path, sr=None)\n",
    "                \n",
    "                # Vérifications\n",
    "                if len(y) < sr * 0.5:  # Moins de 0.5s\n",
    "                    issues.append({\n",
    "                        'file': str(audio_path),\n",
    "                        'issue': 'Too short',\n",
    "                        'duration': len(y) / sr\n",
    "                    })\n",
    "                \n",
    "                if np.max(np.abs(y)) < 0.01:  # Trop silencieux\n",
    "                    issues.append({\n",
    "                        'file': str(audio_path),\n",
    "                        'issue': 'Too quiet',\n",
    "                        'max_amp': np.max(np.abs(y))\n",
    "                    })\n",
    "                    \n",
    "                if np.any(np.isnan(y)) or np.any(np.isinf(y)):\n",
    "                    issues.append({\n",
    "                        'file': str(audio_path),\n",
    "                        'issue': 'Invalid values (NaN/Inf)'\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                issues.append({\n",
    "                    'file': str(audio_path),\n",
    "                    'issue': f'Load error: {str(e)}'\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "# Vérifier train set\n",
    "print(\"Checking data quality...\")\n",
    "quality_issues = check_data_quality(TRAIN_DIR)\n",
    "\n",
    "if len(quality_issues) > 0:\n",
    "    print(f\"\\n️ Found {len(quality_issues)} issues:\")\n",
    "    print(quality_issues)\n",
    "else:\n",
    "    print(\"\\n No quality issues found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Résumé de l'Exploration\n",
    "\n",
    "### Points Clés:\n",
    "1. **Nombre de locuteurs**: [À remplir après exécution]\n",
    "2. **Total fichiers audio**: [À remplir après exécution]\n",
    "3. **Durée moyenne**: [À remplir après exécution]\n",
    "4. **Qualité des données**: [À remplir après exécution]\n",
    "\n",
    "### Observations:\n",
    "- [Vos observations ici]\n",
    "\n",
    "### Recommandations:\n",
    "- [Vos recommandations ici]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder un rapport\n",
    "report = {\n",
    "    'dataset': 'train',\n",
    "    'num_speakers': len(train_stats),\n",
    "    'total_files': train_stats['num_files'].sum(),\n",
    "    'avg_files_per_speaker': train_stats['num_files'].mean(),\n",
    "    'avg_duration': audio_stats['duration'].mean(),\n",
    "    'avg_rms': audio_stats['rms'].mean(),\n",
    "    'num_issues': len(quality_issues)\n",
    "}\n",
    "\n",
    "print(\"\\n=== DATA EXPLORATION REPORT ===\")\n",
    "for key, value in report.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Sauvegarder\n",
    "import json\n",
    "with open('../outputs/data_exploration_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "    \n",
    "print(\"\\nReport saved to: outputs/data_exploration_report.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
