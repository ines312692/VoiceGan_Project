#  Guide de D√©marrage Rapide - VoiceGAN

## Installation (5 minutes)

```bash
# 1. Cloner le repository
git clone <repository-url>
cd VoiceGan_Project

# 2. Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# OU
venv\Scripts\activate  # Windows

# 3. Installer les d√©pendances
pip install -r requirements.txt
pip install -e .
```

## T√©l√©charger des Donn√©es (Option rapide)

### Option 1: Dataset VCTK (Recommand√©)
```bash
# T√©l√©charger VCTK
wget https://datashare.ed.ac.uk/bitstream/handle/10283/3443/VCTK-Corpus-0.92.zip

# Extraire
unzip VCTK-Corpus-0.92.zip -d raw_data/

# Pr√©parer les donn√©es
python scripts/prepare_data.py \
    --input_dir raw_data/VCTK-Corpus/wav48_silence_trimmed \
    --output_dir data/
```

### Option 2: Vos propres enregistrements
```bash
# Structure requise:
# raw_data/
#   speaker_A/
#     audio1.wav
#     audio2.wav
#   speaker_B/
#     audio1.wav
#     audio2.wav

python scripts/prepare_data.py \
    --input_dir raw_data/ \
    --output_dir data/
```

## Entra√Ænement Rapide (Configuration minimale)

### 1. √âditer la configuration (optionnel)
```bash
nano config/config.yaml
```

Points cl√©s √† ajuster:
- `batch_size`: R√©duire √† 4-8 si m√©moire limit√©e
- `num_epochs`: 50-100 pour tests rapides
- `learning_rate_g/d`: Laisser par d√©faut

### 2. Lancer l'entra√Ænement
```bash
# Mode standard
python scripts/train.py --data_dir data/ --device cuda

# Mode CPU (plus lent)
python scripts/train.py --data_dir data/ --device cpu

# Avec monitoring TensorBoard
tensorboard --logdir logs/
# Ouvrir http://localhost:6006
```

### 3. Surveiller l'entra√Ænement
```bash
# Dans un autre terminal
tensorboard --logdir logs/
```

M√©triques √† surveiller:
- `g_recon` (‚Üì): Qualit√© de reconstruction
- `g_adv` (‚Üí stable): √âquilibre GAN
- `d_total` (‚Üí ~0.5): Discriminateur √©quilibr√©

## Conversion Vocale (2 minutes)

### Via ligne de commande
```bash
python scripts/convert.py \
    --source exemples/source_audio.wav \
    --target exemples/target_reference.wav \
    --output converted_output.wav \
    --checkpoint checkpoints/best_model.pt
```

### Via interface Web (Recommand√©)
```bash
streamlit run app/streamlit_app.py
```

1. Ouvrir http://localhost:8501
2. Uploader audio source (A)
3. Uploader r√©f√©rence cible (B)
4. Cliquer "Convert"
5. T√©l√©charger le r√©sultat

## √âvaluation

```bash
python scripts/evaluate.py \
    --test_dir data/test \
    --checkpoint checkpoints/best_model.pt \
    --output_dir outputs/evaluation \
    --save_audio
```

R√©sultats dans `outputs/evaluation/`:
- `evaluation_results.json`: M√©triques num√©riques
- `audio_samples/`: Exemples audio

## Exemples de R√©sultats Attendus

### Apr√®s 10 epochs
- MCD: ~10-12 dB (acceptable)
- Similarit√©: 0.6-0.7
- Audio: L√©g√®rement robotique

### Apr√®s 50 epochs
- MCD: ~7-9 dB (bon)
- Similarit√©: 0.75-0.85
- Audio: Naturel avec quelques artefacts

### Apr√®s 100+ epochs
- MCD: ~5-7 dB (excellent)
- Similarit√©: 0.85-0.95
- Audio: Tr√®s naturel

## R√©solution de Probl√®mes Courants

###  CUDA out of memory
```yaml
# config/config.yaml
training:
  batch_size: 4  # R√©duire de 16 √† 4
  
audio:
  segment_length: 8192  # R√©duire de 16384
```

###  Training instable (pertes divergent)
```yaml
training:
  learning_rate_g: 0.0001  # R√©duire de 0.0002
  learning_rate_d: 0.00005  # R√©duire de 0.0001
  discriminator_start_epoch: 10  # Augmenter de 5
```

###  Style pas transf√©r√©
```yaml
training:
  lambda_identity: 10.0  # Augmenter de 5.0
  lambda_content: 0.5  # R√©duire de 1.0
```

###  Contenu pas pr√©serv√©
```yaml
training:
  lambda_content: 2.0  # Augmenter de 1.0
  lambda_reconstruction: 15.0  # Augmenter de 10.0
```

## Pipeline de D√©veloppement Complet

### Jour 1: Setup & Exploration
```bash
# 1. Installation
pip install -r requirements.txt

# 2. Explorer donn√©es
jupyter notebook notebooks/01_data_exploration.ipynb

# 3. Test preprocessing
jupyter notebook notebooks/02_preprocessing.ipynb
```

### Jour 2-3: Entra√Ænement Initial
```bash
# Quick test (10 epochs)
python scripts/train.py --data_dir data/ --num_epochs 10

# V√©rifier outputs
python scripts/evaluate.py --test_dir data/test --checkpoint checkpoints/checkpoint_epoch_10.pt
```

### Jour 4-7: Entra√Ænement Complet
```bash
# Full training
python scripts/train.py --data_dir data/ --num_epochs 100

# Monitor avec TensorBoard
tensorboard --logdir logs/
```

### Jour 8: √âvaluation & Fine-tuning
```bash
# √âvaluation compl√®te
python scripts/evaluate.py \
    --test_dir data/test \
    --checkpoint checkpoints/best_model.pt \
    --save_audio

# Ajuster hyperparam√®tres si n√©cessaire
# Reprendre entra√Ænement
python scripts/train.py --resume checkpoints/checkpoint_epoch_100.pt
```

### Jour 9: D√©mo & Documentation
```bash
# Pr√©parer d√©mo
streamlit run app/streamlit_app.py

# G√©n√©rer exemples pour rapport
python scripts/convert.py --source ... --target ... --output demo_samples/
```

## Checklist Projet

- [ ] Installation compl√®te
- [ ] Donn√©es pr√©par√©es (train/val/test)
- [ ] Config ajust√©e pour votre machine
- [ ] Entra√Ænement lanc√© (>50 epochs)
- [ ] TensorBoard configur√©
- [ ] √âvaluation effectu√©e (MCD, similarit√©)
- [ ] Interface Streamlit test√©e
- [ ] Exemples audio sauvegard√©s
- [ ] Rapport r√©dig√©
- [ ] Sch√©ma pipeline cr√©√©

## Ressources Utiles

### Documentation
- `README.md`: Documentation compl√®te
- `docs/`: Documentation technique
- `notebooks/`: Tutoriels interactifs

### Support
- Issues GitHub: Pour bugs
- Documentation PyTorch: https://pytorch.org/docs
- Articles de r√©f√©rence: Voir README

## Prochaines √âtapes

1.  Compl√©tez ce quickstart
2.  Lisez le README complet
3.  Explorez les notebooks
4.  Ajustez la config pour vos besoins
5.  Lancez un entra√Ænement complet
6.  Analysez les r√©sultats
7.  Documentez vos exp√©riences

Bon d√©veloppement ! üé§